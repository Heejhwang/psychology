library(dplyr)
library(rstan)
library(ggplot2)
library(loo)
library(bayesplot)
library(posterior)

# Load data
load("output.RData")

set.seed(2025)

# 1. 데이터 전처리
dat <- dat %>%
  filter(target_mod != "word", priming_type == "no_priming") %>%
  arrange(idcode, trial_index)

minRT <- sapply(allSubjs, function(s) {
  min(dat$rt[dat$idcode == s], na.rm = TRUE)
})

# 3. 비정상적인 반응시간 보정
idx <- which(dat$idcode == 782733 & dat$trial_index == 1)
if (length(idx) == 1 && dat$rt[idx] < 0.05) {
  dat$rt[idx] <- median(dat$rt[dat$idcode == 782733 & dat$trial_index != 1], na.rm = TRUE)
}

# 4. 응답 재코딩
dat$response <- ifelse(dat$nat_cond == "man_made" & dat$acc == 1, "man_made", 
                       ifelse(dat$nat_cond == "man_made" & dat$acc == 0, "natural", 
                              ifelse(dat$nat_cond == "natural" & dat$acc == 1, "natural", 
                                     ifelse(dat$nat_cond == "natural" & dat$acc == 0, "man_made", NA))))

# 5. Stan 입력용 객체 생성
allSubjs <- unique(dat$idcode)
N <- length(allSubjs)
T <- max(table(dat$idcode))  # Max_tr
N_choices <- 2

RT            <- matrix(0, nrow = N, ncol = T)
stimulus_type <- matrix(0, nrow = N, ncol = T)
choice        <- matrix(0, nrow = N, ncol = T)
subtlex_arr   <- matrix(0, nrow = N, ncol = T)
greene_arr   <- matrix(0, nrow = N, ncol = T)
N_tr_cond     <- integer(N)

for (i in seq_len(N)) {
  tmp <- filter(dat, idcode == allSubjs[i])
  nTrials <- nrow(tmp)
  
  RT[i, 1:nTrials]            <- tmp$rt
  stimulus_type[i, 1:nTrials] <- ifelse(tmp$nat_cond == "natural", 1, 2)
  choice[i, 1:nTrials]        <- ifelse(tmp$response == "man_made", 2, 1)
  subtlex_arr[i, 1:nTrials]   <- scale(tmp$subtlex_log)
  greene_arr[i, 1:nTrials]   <- scale(tmp$greene_log)
  N_tr_cond[i] <- nTrials
}

# 6. Stan 데이터 리스트
dataList <- list(
  N = N,
  Max_tr = T,
  N_choices = N_choices,
  N_tr_cond = N_tr_cond,
  RT = RT,
  choice = choice,
  subtlex = subtlex_arr,
  greene = greene_arr,
  minRT = minRT,
  stimulus_type = stimulus_type
)


model_lba <- stan_model(file = "LBA_word_obj_non_centered.stan")

init_fn <- function() {
  list(
    mu_int = rnorm(1, 3.19, 0.01),
    sigma_int = runif(1, 0.55, 0.60),
    
    mu_A = rnorm(1, 0.34, 0.01),
    sigma_A = runif(1, 0.20, 0.25),
    
    mu_d = rnorm(1, 0.41, 0.01),
    sigma_d = runif(1, 0.68, 0.73),
    
    mu_tau = rnorm(1, 0.01, 0.001),
    sigma_tau = runif(1, 0.31, 0.33),
    
    mu_slope1 = rnorm(1, 0.11, 0.01),
    sigma_slope1 = runif(1, 0.04, 0.06),
    
    mu_slope2 = rnorm(1, 0.05, 0.005),
    sigma_slope2 = runif(1, 0.02, 0.04),
    
    A_raw = rnorm(N, 0, 0.05),
    d_raw = rnorm(N, 0, 0.05),
    tau_raw = rnorm(N, 0, 0.05),
    intercept_raw = rnorm(N, 0, 0.05),
    slope1_raw = rnorm(N, 0, 0.05),
    slope2_raw = rnorm(N, 0, 0.05)
  )
}

# 8. Stan 실행
output_lba2 <- sampling(
  object = model_lba,
  data   = dataList,
  init   = init_fn,
  iter   = 2000,
  warmup = 1000,
  chains = 4,
  cores  = 4,                  
  control = list(adapt_delta = 0.95, max_treedepth = 12),
  refresh = 50,
  verbose = TRUE,
  
  pars = c(
    # hyper‐parameters
    "intercept",  "mu_int",  "sigma_int",
    "slope1", "mu_slope1", "sigma_slope1",
    "slope2", "mu_slope2", "sigma_slope2",
    "A",      "mu_A",    "sigma_A",
    "d",      "mu_d",    "sigma_d",
    "tau",    "mu_tau",  "sigma_tau",
    "A_raw",  "d_raw", "tau_raw", "intercept_raw", "slope1_raw", "slope2_raw",
    
    # log-likelihood vector
    "log_lik"
    # pred
        ,"y_pred"
  )
)

summary_table <- summary(output_lba2)$summary
write.table(summary_table, file = "posterior_summary_lba2.txt", sep = "\t", quote = FALSE)

qpairs(output_lba2, pars = c("mu_A",    "sigma_A",
                            "mu_d",    "sigma_d",
                            "mu_tau",  "sigma_tau"))
pairs(output_lba2, pars = c("mu_int",  "sigma_int",
                           "slope1", "slope2"))

# Extract posterior summary
print(output_lba2, pars = c(
  "mu_int",    "sigma_int",
  "slope",
  "mu_A",      "sigma_A",
  "mu_d",      "sigma_d",
  "mu_tau",    "sigma_tau"
))

traceplot(output_lba2, pars = "A", inc_warmup = FALSE, size =0.05)
traceplot(output_lba2, pars = "d", inc_warmup = FALSE, size =0.05)
traceplot(output_lba2, pars = "tau", inc_warmup = FALSE, size =0.05)
traceplot(output_lba2, pars = "intercept", inc_warmup = FALSE, size =0.05)
traceplot(output_lba2, pars = "slope1", inc_warmup = FALSE, size =0.05)
traceplot(output_lba2, pars = "slope2", inc_warmup = FALSE, size =0.05)

traceplot(output_lba2, pars = c("mu_int", "mu_slope1", "mu_slope2", "mu_d", "mu_A", "mu_tau", "sigma_int", "sigma_slope1", "sigma_slope2", "sigma_d", "sigma_A", "sigma_tau"), inc_warmup = FALSE, size =0.05)
traceplot(output_lba2, pars = c("sigma_int", "sigma_d", "sigma_A", "sigma_tau"), inc_warmup = FALSE, size = 0.05)
traceplot(output_lba2, pars = c("A_raw[1]", "d[1]", "tau[1]", "intercept[1]", "slope"), inc_warmup = FALSE, size = 0.05)
traceplot(output_lba2, pars = c("mu_int", "mu_d", "mu_A", "mu_tau"), inc_warmup = T, size =0.05)
traceplot(output_lba2, pars = c("sigma_int", "sigma_d", "sigma_A", "sigma_tau"), inc_warmup = T, size = 0.05)
traceplot(output_lba2, pars = c("A_raw[1]", "d[1]", "tau[1]", "intercept[1]", "slope1", "slope2"), inc_warmup = T, size = 0.05)
traceplot(output_lba2, pars = "tau")
traceplot(output__lba, pars = "A_raw")

# 1. posterior array
posterior_array <- as.array(output_lba2)

# 2. NUTS 파라미터 전체를 long-format으로
nuts_df <- nuts_params(output_lba2)

# 3. 평행좌표 플롯
mcmc_parcoord(
  posterior_array,
  pars = c("mu_A", "sigma_A", "mu_d", "sigma_d", "mu_tau", "sigma_tau", "mu_int", "sigma_int", "slope"),
  np = nuts_df
)

help("posterior-package")

printprintprint(posterior_summary[, c("mean", "2.5%", "97.5%")])

summary(output_lba2)$summary[ , c("mean", "sd", "n_eff", "Rhat")]


# drift_subtlex_output에서 각 참가자별로 100개의 트라이얼에 대한 평균 계산
mean_drift_rate <- apply(parameters$drift_subtlex_output, 2, mean)
print(mean_drift_rate)

plot(output_lba2, show_density = T, pars="A")
plot(output_lba2, show_density = T, pars="d")
plot(output_lba2, show_density = T, pars="tau")
plot(output_lba2, show_density = T, pars="intercept")
plot(output_lba2, show_density = T, pars="slope1")
plot(output_lba2, show_density = T, pars="slope2")

plot(output_lba2, show_density = T, pars=c("mu_int", "mu_slope1", "mu_slope2", "mu_d", "mu_A", "mu_tau", "sigma_int", "sigma_slope1", "sigma_slope2", "sigma_d", "sigma_A", "sigma_tau"))
plot(output_lba2, show_density = T, pars=c("mu_int", "mu_slo", "mu_d", "mu_A", "mu_tau"))
plot(output_lba2, show_density = T, pars=c("sigma_int", "sigma_slo", "sigma_d", "sigma_A", "sigma_tau"))
plot(output_lba2, show_density = T, pars="d1_intercept")
plot(output_lba2, show_density = T, pars="d1_slope")

check_divergences(output_lba2)

posterior <- as.array(output_lba2)
div <- get_sampler_params(output_lba2, inc_warmup = FALSE)
divergent <- do.call(rbind, div)[, "divergent__"] == 1

# Stan 모델의 요약 결과 얻기
fit_summary <- summary(output_lba2)

# Rhat 값 추출
rhat_values <- fit_summary$summary[, "Rhat"]

# Rhat 값 출력
print(rhat_values)

check_hmc_diagnostics(output_lba2)

# COMPUTE LOOIC  -----------------------------------------

ll <- extract_log_lik(output_lba2, parameter_name = "log_lik", merge_chains = TRUE)

looic <- loo(ll)$looic

loo(ll, moment_match = TRUE)

# posterior 샘플 추출
samples <- rstan::extract(output_lba2)

# d1_slope의 평균 계산 (샘플 평균)
mean_d1_slope_ch1 <- mean(samples$d1_slope_ch1)
print(mean_d1_slope_ch1)
mean_d1_slope_ch2 <- mean(samples$d1_slope_ch2)
print(mean_d1_slope_ch2)

# 전체 값의 분포
summary(data$subtlex_log)
min(data$rt/1000)

params_to_plot <- c("d[1]", "A[1]", "tau[1]")  # 또는 더 많은 파라미터

divergent <- get_sampler_params(output_lba2, inc_warmup = FALSE)[[1]][, "divergent__"] == 1
posterior_samples <- extract(output_lba2)

# 샘플 추출
post <- extract(output_lba2)
N <- dim(post$RT)[1]
S <- length(post$tau[,1])  # 샘플 수
set.seed(123)

help("extract_log_lik")
